{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import sys\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final = pd.read_csv(\"/Users/tedlinghu/Desktop/Luo_Rotation/luorotation/final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(\"Unnamed: 0\" , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "\n",
    "for train_idx, test_idx in split.split(X, y):\n",
    "    x_train, x_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27680, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6921, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALIVE      25979\n",
       "EXPIRED     1701\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALIVE      6496\n",
       "EXPIRED     425\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = 42)\n",
    "\n",
    "for train_idx, val_idx in split.split(x_train, y_train):\n",
    "    x_train, x_val = x_train.iloc[train_idx], x_train.iloc[val_idx]\n",
    "    y_train, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20760, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALIVE      19484\n",
       "EXPIRED     1276\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALIVE      6495\n",
       "EXPIRED     425\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALIVE      19484\n",
       "EXPIRED     1276\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "alive_idx = y_train[y_train == 'ALIVE'].index\n",
    "expired_idx = y_train[y_train != 'ALIVE'].index\n",
    "\n",
    "\n",
    "\n",
    "downsample = resample(x_train.loc[alive_idx], n_samples = 1526, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_downsample = y_train.loc[downsample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29028    ALIVE\n",
       "25521    ALIVE\n",
       "3788     ALIVE\n",
       "24197    ALIVE\n",
       "4223     ALIVE\n",
       "         ...  \n",
       "23911    ALIVE\n",
       "27483    ALIVE\n",
       "9313     ALIVE\n",
       "9203     ALIVE\n",
       "22756    ALIVE\n",
       "Name: label, Length: 1526, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_labels = pd.concat([y_train_downsample, y_train.loc[expired_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([29028, 25521,  3788, 24197,  4223, 22912, 23920,  2040,  6701,\n",
       "            24910,\n",
       "            ...\n",
       "            25539, 22225,  7523,  3982,  3797, 23896,  7036, 24665, 14538,\n",
       "            30581],\n",
       "           dtype='int64', length=2802)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample_labels.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_df = pd.concat([downsample, x_train.loc[expired_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>admissionweight</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>respiratoryrate</th>\n",
       "      <th>sodium</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>meanbp</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>gender_Unknown</th>\n",
       "      <th>ethnicity_African American</th>\n",
       "      <th>ethnicity_Asian</th>\n",
       "      <th>ethnicity_Caucasian</th>\n",
       "      <th>ethnicity_Hispanic</th>\n",
       "      <th>ethnicity_Native American</th>\n",
       "      <th>ethnicity_Other/Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29028</td>\n",
       "      <td>62</td>\n",
       "      <td>65.9</td>\n",
       "      <td>167.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>108</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25521</td>\n",
       "      <td>79</td>\n",
       "      <td>55.2</td>\n",
       "      <td>152.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>94</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3788</td>\n",
       "      <td>69</td>\n",
       "      <td>71.2</td>\n",
       "      <td>182.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>54</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24197</td>\n",
       "      <td>61</td>\n",
       "      <td>62.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>39.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>111</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4223</td>\n",
       "      <td>77</td>\n",
       "      <td>92.0</td>\n",
       "      <td>152.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>96</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23896</td>\n",
       "      <td>68</td>\n",
       "      <td>70.0</td>\n",
       "      <td>172.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>139</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7036</td>\n",
       "      <td>73</td>\n",
       "      <td>91.4</td>\n",
       "      <td>157.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>106</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24665</td>\n",
       "      <td>57</td>\n",
       "      <td>56.7</td>\n",
       "      <td>170.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>142</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14538</td>\n",
       "      <td>52</td>\n",
       "      <td>50.8</td>\n",
       "      <td>180.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>139</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30581</td>\n",
       "      <td>72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>50</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2802 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  admissionweight  admissionheight  respiratoryrate  sodium  \\\n",
       "29028   62             65.9            167.6             40.0   131.0   \n",
       "25521   79             55.2            152.4             24.0   138.0   \n",
       "3788    69             71.2            182.9             10.0   138.0   \n",
       "24197   61             62.4            162.6             39.0   138.0   \n",
       "4223    77             92.0            152.4              4.0   141.0   \n",
       "...    ...              ...              ...              ...     ...   \n",
       "23896   68             70.0            172.7              5.0   144.0   \n",
       "7036    73             91.4            157.5             42.0   138.0   \n",
       "24665   57             56.7            170.2             33.0   139.0   \n",
       "14538   52             50.8            180.3             49.0   142.0   \n",
       "30581   72            100.0            177.0             33.0   135.0   \n",
       "\n",
       "       heartrate  meanbp  gender_Female  gender_Male  gender_Other  \\\n",
       "29028        108    65.0              0            1             0   \n",
       "25521         94    44.0              1            0             0   \n",
       "3788          54    54.0              0            1             0   \n",
       "24197        111    48.0              0            1             0   \n",
       "4223          96    53.0              1            0             0   \n",
       "...          ...     ...            ...          ...           ...   \n",
       "23896        139    40.0              0            1             0   \n",
       "7036         106    40.0              1            0             0   \n",
       "24665        142    46.0              1            0             0   \n",
       "14538        139    40.0              0            1             0   \n",
       "30581         50    64.0              1            0             0   \n",
       "\n",
       "       gender_Unknown  ethnicity_African American  ethnicity_Asian  \\\n",
       "29028               0                           0                0   \n",
       "25521               0                           0                0   \n",
       "3788                0                           0                0   \n",
       "24197               0                           0                0   \n",
       "4223                0                           0                0   \n",
       "...               ...                         ...              ...   \n",
       "23896               0                           0                0   \n",
       "7036                0                           0                0   \n",
       "24665               0                           0                0   \n",
       "14538               0                           0                0   \n",
       "30581               0                           1                0   \n",
       "\n",
       "       ethnicity_Caucasian  ethnicity_Hispanic  ethnicity_Native American  \\\n",
       "29028                    1                   0                          0   \n",
       "25521                    1                   0                          0   \n",
       "3788                     1                   0                          0   \n",
       "24197                    1                   0                          0   \n",
       "4223                     0                   1                          0   \n",
       "...                    ...                 ...                        ...   \n",
       "23896                    1                   0                          0   \n",
       "7036                     1                   0                          0   \n",
       "24665                    1                   0                          0   \n",
       "14538                    1                   0                          0   \n",
       "30581                    0                   0                          0   \n",
       "\n",
       "       ethnicity_Other/Unknown  \n",
       "29028                        0  \n",
       "25521                        0  \n",
       "3788                         0  \n",
       "24197                        0  \n",
       "4223                         0  \n",
       "...                        ...  \n",
       "23896                        0  \n",
       "7036                         0  \n",
       "24665                        0  \n",
       "14538                        0  \n",
       "30581                        0  \n",
       "\n",
       "[2802 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(downsample_df, downsample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val[y_val == \"ALIVE\"] = 0\n",
    "y_val[y_val == \"EXPIRED\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563      0\n",
       "2274     0\n",
       "17670    0\n",
       "20656    0\n",
       "4045     0\n",
       "        ..\n",
       "30068    0\n",
       "27996    0\n",
       "3115     1\n",
       "5392     1\n",
       "10581    1\n",
       "Name: label, Length: 6920, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred[val_pred == \"ALIVE\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred[val_pred == \"EXPIRED\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def show_metrics(pred, truth):\n",
    "    print(\"confusion matrix\", confusion_matrix(pred, truth))\n",
    "    print(\"roc auc\", roc_auc_score(pred, truth))\n",
    "    print(\"f1\", f1_score(pred, truth))\n",
    "    print(\"precision\", average_precision_score(pred, truth))\n",
    "    print(\"recall\", recall_score(pred, truth))\n",
    "    print(\"mcc\", matthews_corrcoef(pred, truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[5014  210]\n",
      " [1481  215]]\n",
      "roc auc 0.5432848933803346\n",
      "f1 0.20273455917020272\n",
      "precision 0.27814747422581204\n",
      "recall 0.1267688679245283\n",
      "mcc 0.15509464859643496\n"
     ]
    }
   ],
   "source": [
    "show_metrics(list(val_pred), list(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1,5,10,50,100,200]\n",
    "max_depth = [1,2,5,10,20,30]\n",
    "min_samples_split = [2,5,10,15,50,100]\n",
    "min_samples_leaf = [1,2,5,10]\n",
    "\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(rf, hyperF, cv = 5, scoring = \"f1_weighted\", return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_labels[downsample_labels == \"ALIVE\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_labels[downsample_labels == \"EXPIRED\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [1, 2, 5, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 5, 10],\n",
       "                         'min_samples_split': [2, 5, 10, 15, 50, 100],\n",
       "                         'n_estimators': [1, 5, 10, 50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(downsample_df, list(downsample_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56971458, 0.59850387, 0.58087343, 0.59164785, 0.5821856 ,\n",
       "       0.57848418, 0.56582821, 0.57912987, 0.56156394, 0.60170692,\n",
       "       0.5846632 , 0.57781575, 0.56079205, 0.55313377, 0.5644188 ,\n",
       "       0.58224267, 0.58674134, 0.58182168, 0.57017793, 0.5930997 ,\n",
       "       0.5835508 , 0.5904278 , 0.57258715, 0.57553763, 0.5531056 ,\n",
       "       0.54454472, 0.58130687, 0.58929054, 0.58491648, 0.59207382,\n",
       "       0.5116827 , 0.56743505, 0.61113288, 0.58740325, 0.5822235 ,\n",
       "       0.58345571, 0.52653172, 0.60032726, 0.56334909, 0.5772481 ,\n",
       "       0.57220148, 0.57602323, 0.55466952, 0.54731596, 0.5710803 ,\n",
       "       0.58838579, 0.58575182, 0.58153167, 0.60530145, 0.58991062,\n",
       "       0.59092633, 0.58289861, 0.58188409, 0.58382626, 0.57910319,\n",
       "       0.61097451, 0.5476089 , 0.57507782, 0.58166344, 0.58123344,\n",
       "       0.44287484, 0.60272841, 0.6063751 , 0.59665466, 0.5705785 ,\n",
       "       0.5808735 , 0.53671643, 0.56715   , 0.57010063, 0.59328605,\n",
       "       0.57599554, 0.58137092, 0.53899343, 0.58897295, 0.57561281,\n",
       "       0.58994149, 0.58044359, 0.57694886, 0.55122784, 0.56901359,\n",
       "       0.5914423 , 0.59032607, 0.58014438, 0.57819409, 0.58032292,\n",
       "       0.57640617, 0.59206738, 0.57036977, 0.58006083, 0.57803864,\n",
       "       0.53775935, 0.6025829 , 0.59850259, 0.59704483, 0.58311762,\n",
       "       0.5888502 , 0.55687002, 0.5892967 , 0.58308603, 0.59661306,\n",
       "       0.56242847, 0.5854563 , 0.58927723, 0.56144104, 0.59082568,\n",
       "       0.5906428 , 0.5806271 , 0.58289325, 0.53232666, 0.55756182,\n",
       "       0.58925383, 0.58438419, 0.58488784, 0.58195849, 0.57026432,\n",
       "       0.58078992, 0.56844023, 0.5833827 , 0.57490894, 0.57838464,\n",
       "       0.59524948, 0.57948565, 0.59598616, 0.58597646, 0.58346867,\n",
       "       0.58740637, 0.54090527, 0.59159139, 0.57736204, 0.58199529,\n",
       "       0.59807237, 0.57911623, 0.44850152, 0.58231339, 0.60606599,\n",
       "       0.59562142, 0.58077489, 0.58511316, 0.49940918, 0.55515008,\n",
       "       0.57665323, 0.60201499, 0.57890153, 0.58612869, 0.59812353,\n",
       "       0.61460772, 0.64583712, 0.64863471, 0.65057242, 0.65882176,\n",
       "       0.54190239, 0.63660506, 0.62983305, 0.65713931, 0.65533059,\n",
       "       0.65587263, 0.5925543 , 0.62440269, 0.64010264, 0.65680189,\n",
       "       0.66406697, 0.6580621 , 0.59725757, 0.62365076, 0.63773305,\n",
       "       0.64497818, 0.65635647, 0.65576345, 0.56611623, 0.63651697,\n",
       "       0.63839565, 0.66237127, 0.65651566, 0.6548703 , 0.57829987,\n",
       "       0.62973328, 0.62811832, 0.65091167, 0.65764507, 0.66146524,\n",
       "       0.57636393, 0.63554391, 0.64774849, 0.65289077, 0.65472758,\n",
       "       0.66328762, 0.52357002, 0.60272788, 0.64062087, 0.65668536,\n",
       "       0.6574401 , 0.66255349, 0.59740932, 0.63764164, 0.64494283,\n",
       "       0.65837677, 0.66001217, 0.65561086, 0.58245947, 0.6263577 ,\n",
       "       0.64777857, 0.65541729, 0.65451264, 0.65553337, 0.59743111,\n",
       "       0.62843447, 0.65041878, 0.6533406 , 0.65584448, 0.65588421,\n",
       "       0.56357578, 0.64059755, 0.64638161, 0.65782519, 0.65582288,\n",
       "       0.65573437, 0.5758337 , 0.62269289, 0.64089554, 0.65220255,\n",
       "       0.65811839, 0.65558087, 0.57752716, 0.61282522, 0.62815694,\n",
       "       0.65357458, 0.65988741, 0.66106428, 0.60704585, 0.64629959,\n",
       "       0.64277726, 0.66258839, 0.65386451, 0.65614577, 0.53150369,\n",
       "       0.62924424, 0.63908602, 0.64787415, 0.65796079, 0.65251846,\n",
       "       0.58730535, 0.64874383, 0.65428058, 0.65428729, 0.65732545,\n",
       "       0.6584315 , 0.57951432, 0.62690802, 0.64744472, 0.65942104,\n",
       "       0.65262175, 0.65825459, 0.60809513, 0.62902054, 0.64041399,\n",
       "       0.65067144, 0.66315726, 0.65840004, 0.57511032, 0.6149884 ,\n",
       "       0.64927677, 0.65487652, 0.65796285, 0.66687442, 0.60897703,\n",
       "       0.62121177, 0.63697961, 0.65020046, 0.65583873, 0.65608756,\n",
       "       0.58172781, 0.62593538, 0.62161334, 0.65482078, 0.65403984,\n",
       "       0.6623341 , 0.57400024, 0.63791704, 0.63789066, 0.66447539,\n",
       "       0.65965408, 0.65979675, 0.60523926, 0.63543372, 0.63631308,\n",
       "       0.648464  , 0.65803429, 0.66220304, 0.62328533, 0.66811684,\n",
       "       0.68460854, 0.68454446, 0.68803066, 0.69285373, 0.62904381,\n",
       "       0.65869012, 0.67611664, 0.68222496, 0.68861415, 0.68902033,\n",
       "       0.64658431, 0.66649468, 0.67344398, 0.68111517, 0.68383906,\n",
       "       0.6943914 , 0.62143355, 0.6666415 , 0.67428293, 0.67906025,\n",
       "       0.68524478, 0.68941383, 0.63074033, 0.67329045, 0.67418102,\n",
       "       0.68296196, 0.684537  , 0.69262948, 0.63229014, 0.66284273,\n",
       "       0.67697726, 0.68624358, 0.68775695, 0.68949062, 0.63092901,\n",
       "       0.66993293, 0.67299917, 0.68587582, 0.68580252, 0.68925961,\n",
       "       0.61383438, 0.6571972 , 0.68076482, 0.69341634, 0.68652924,\n",
       "       0.6919062 , 0.63382159, 0.6600512 , 0.68442999, 0.67702063,\n",
       "       0.69446184, 0.68952172, 0.63111308, 0.67474121, 0.67753977,\n",
       "       0.67791933, 0.69019124, 0.68824276, 0.64790481, 0.66710098,\n",
       "       0.6793931 , 0.69065804, 0.69368122, 0.68967641, 0.63200294,\n",
       "       0.65105598, 0.67889403, 0.6947895 , 0.68778851, 0.68702424,\n",
       "       0.64095084, 0.65951728, 0.67691216, 0.68323955, 0.6909842 ,\n",
       "       0.69204578, 0.62453295, 0.67531599, 0.6714423 , 0.68674965,\n",
       "       0.69436176, 0.6936247 , 0.62120231, 0.66175263, 0.67972319,\n",
       "       0.68514015, 0.69407758, 0.69366232, 0.65310256, 0.66935841,\n",
       "       0.67986415, 0.68620018, 0.69014093, 0.69016034, 0.65213736,\n",
       "       0.67604416, 0.6896538 , 0.68817075, 0.69282382, 0.69335083,\n",
       "       0.63815855, 0.65998049, 0.67687764, 0.68890164, 0.6868771 ,\n",
       "       0.69339467, 0.61970684, 0.67582893, 0.68087017, 0.68253599,\n",
       "       0.69109131, 0.69265142, 0.62005335, 0.66209728, 0.67274673,\n",
       "       0.68839528, 0.68978603, 0.69552853, 0.61637868, 0.67036528,\n",
       "       0.68205613, 0.68479791, 0.68674983, 0.69483139, 0.62609257,\n",
       "       0.66650462, 0.67810498, 0.68697955, 0.6857362 , 0.69222069,\n",
       "       0.63058375, 0.67010421, 0.67477175, 0.69547914, 0.69256174,\n",
       "       0.69091956, 0.64316991, 0.67075188, 0.67627132, 0.69180922,\n",
       "       0.68713017, 0.68866534, 0.62362053, 0.66125444, 0.67761906,\n",
       "       0.69383492, 0.69530425, 0.69519853, 0.61649976, 0.65167995,\n",
       "       0.6826006 , 0.69232202, 0.69643513, 0.69397593, 0.62386061,\n",
       "       0.67976128, 0.67131222, 0.70177254, 0.69574358, 0.70074782,\n",
       "       0.62782503, 0.67129037, 0.67818882, 0.70187441, 0.69747464,\n",
       "       0.69954261, 0.64283579, 0.66533194, 0.69031383, 0.69532148,\n",
       "       0.69831287, 0.69597387, 0.63989994, 0.6743419 , 0.68702698,\n",
       "       0.69417705, 0.69726534, 0.69797757, 0.62933186, 0.6602081 ,\n",
       "       0.67013927, 0.69468426, 0.69651967, 0.69527125, 0.60014719,\n",
       "       0.65698088, 0.67573454, 0.69290137, 0.69899624, 0.69674601,\n",
       "       0.61877902, 0.67517422, 0.67690262, 0.69554667, 0.70146915,\n",
       "       0.70267598, 0.61786675, 0.67388924, 0.68360108, 0.69664476,\n",
       "       0.69856301, 0.69563016, 0.6297759 , 0.67433468, 0.68382108,\n",
       "       0.69220285, 0.69786347, 0.69653574, 0.63783532, 0.67665788,\n",
       "       0.68646268, 0.68962335, 0.6979189 , 0.69684098, 0.61186146,\n",
       "       0.66436302, 0.6833391 , 0.6967354 , 0.69173441, 0.69630135,\n",
       "       0.62872561, 0.67307484, 0.67913206, 0.69500214, 0.69742603,\n",
       "       0.6962542 , 0.6192408 , 0.6771951 , 0.67870522, 0.69729467,\n",
       "       0.6988859 , 0.69991072, 0.62682203, 0.66360095, 0.68303401,\n",
       "       0.70067504, 0.69845526, 0.69801983, 0.61859916, 0.67628388,\n",
       "       0.68472508, 0.69123332, 0.69792888, 0.69826294, 0.64777465,\n",
       "       0.67767739, 0.68788816, 0.69863734, 0.69817279, 0.69796567,\n",
       "       0.62098118, 0.67543673, 0.67831885, 0.7007443 , 0.69856041,\n",
       "       0.69354213, 0.63434988, 0.67196829, 0.68255429, 0.69628751,\n",
       "       0.70315198, 0.70082994, 0.61781729, 0.66783567, 0.68250022,\n",
       "       0.69562575, 0.69593252, 0.69928164, 0.61853969, 0.67101314,\n",
       "       0.68439517, 0.69385972, 0.69812075, 0.70064781, 0.62144789,\n",
       "       0.67362681, 0.68052939, 0.69419545, 0.70410006, 0.69889223,\n",
       "       0.61723303, 0.67039484, 0.6869138 , 0.69198139, 0.69395128,\n",
       "       0.6984974 , 0.61034079, 0.63652839, 0.6514119 , 0.68695407,\n",
       "       0.68618603, 0.6939992 , 0.59847988, 0.63597363, 0.67442997,\n",
       "       0.68065255, 0.68849799, 0.68574722, 0.59260095, 0.66464584,\n",
       "       0.67632861, 0.68924768, 0.6968069 , 0.69973058, 0.61801201,\n",
       "       0.64960785, 0.67540969, 0.69484556, 0.69233231, 0.69951858,\n",
       "       0.63059807, 0.66506435, 0.684087  , 0.69745365, 0.69740351,\n",
       "       0.6959653 , 0.63297567, 0.67713013, 0.68989142, 0.69616773,\n",
       "       0.69817977, 0.69347045, 0.60680164, 0.64266084, 0.66628835,\n",
       "       0.6882098 , 0.689189  , 0.69580922, 0.61012485, 0.64911788,\n",
       "       0.6693404 , 0.69157395, 0.69009263, 0.69695218, 0.60365797,\n",
       "       0.65290565, 0.67736262, 0.68731671, 0.6983759 , 0.69764709,\n",
       "       0.60020926, 0.66165802, 0.68012611, 0.70357789, 0.69479954,\n",
       "       0.69943487, 0.62707749, 0.67429549, 0.69131382, 0.69475999,\n",
       "       0.69543895, 0.6997583 , 0.63886848, 0.66615388, 0.68860997,\n",
       "       0.694598  , 0.69341108, 0.69666358, 0.59733915, 0.66198486,\n",
       "       0.68377738, 0.69602781, 0.69883589, 0.69361254, 0.59894238,\n",
       "       0.6620618 , 0.67273478, 0.69294235, 0.69253546, 0.69588771,\n",
       "       0.60023216, 0.66715894, 0.68556007, 0.69109749, 0.69881401,\n",
       "       0.6992974 , 0.60615258, 0.66214197, 0.68430663, 0.69474863,\n",
       "       0.69363095, 0.69810899, 0.63862626, 0.67309884, 0.6994594 ,\n",
       "       0.69801706, 0.69511432, 0.69437409, 0.62029474, 0.67213318,\n",
       "       0.68779471, 0.70005384, 0.69816225, 0.69630352, 0.62599982,\n",
       "       0.67648481, 0.6839083 , 0.69628913, 0.69770574, 0.69185944,\n",
       "       0.61288838, 0.66741945, 0.68959399, 0.69589174, 0.69401682,\n",
       "       0.69917932, 0.6368176 , 0.65810339, 0.68440961, 0.69533015,\n",
       "       0.69924216, 0.69985022, 0.62663981, 0.672418  , 0.68429207,\n",
       "       0.69087007, 0.6980567 , 0.69718709, 0.63973456, 0.66829992,\n",
       "       0.68205203, 0.69216374, 0.69432228, 0.70165682, 0.64867691,\n",
       "       0.67069698, 0.67547779, 0.69243085, 0.69640732, 0.69439138,\n",
       "       0.60870017, 0.64307567, 0.66648282, 0.6792508 , 0.68067372,\n",
       "       0.68626861, 0.595499  , 0.64568656, 0.65502115, 0.69343584,\n",
       "       0.69205407, 0.6871651 , 0.59047284, 0.66294032, 0.67810476,\n",
       "       0.69408747, 0.69195268, 0.69862418, 0.60067313, 0.65690115,\n",
       "       0.67520874, 0.69742871, 0.69749702, 0.70160844, 0.61916175,\n",
       "       0.67350181, 0.6786754 , 0.69987935, 0.69301509, 0.69505249,\n",
       "       0.63680642, 0.68301127, 0.69034363, 0.69407683, 0.69901718,\n",
       "       0.69644226, 0.603921  , 0.6488347 , 0.67026822, 0.68700655,\n",
       "       0.68788732, 0.69591308, 0.60618904, 0.64683361, 0.66952937,\n",
       "       0.68925351, 0.69620077, 0.69523531, 0.62655858, 0.66072405,\n",
       "       0.67026141, 0.69123876, 0.70211492, 0.69590985, 0.60607554,\n",
       "       0.67088725, 0.68448532, 0.69712639, 0.69367517, 0.6989764 ,\n",
       "       0.62472808, 0.6765717 , 0.68881205, 0.69612764, 0.69280021,\n",
       "       0.70041789, 0.62845767, 0.67569635, 0.68624378, 0.68836201,\n",
       "       0.69852367, 0.69583434, 0.61706454, 0.67079573, 0.68343289,\n",
       "       0.69232831, 0.70056225, 0.69825634, 0.60555687, 0.65436146,\n",
       "       0.68020678, 0.69658643, 0.69993876, 0.69722022, 0.61425289,\n",
       "       0.65558385, 0.67533385, 0.69276487, 0.69267627, 0.69975044,\n",
       "       0.60567611, 0.66347719, 0.67134126, 0.69106533, 0.69821564,\n",
       "       0.69631685, 0.63934577, 0.67116126, 0.68820127, 0.69763687,\n",
       "       0.69447544, 0.69486433, 0.61821216, 0.68144416, 0.69031316,\n",
       "       0.69732297, 0.70424923, 0.69837938, 0.62035032, 0.67437321,\n",
       "       0.68645002, 0.69512882, 0.69539731, 0.69895493, 0.6373958 ,\n",
       "       0.66242137, 0.68287852, 0.69639097, 0.70069989, 0.69832548,\n",
       "       0.63668367, 0.66536716, 0.68940162, 0.69455959, 0.69583631,\n",
       "       0.69723069, 0.6204132 , 0.67855547, 0.68877674, 0.69733684,\n",
       "       0.69439027, 0.69649609, 0.64147118, 0.67352989, 0.68863531,\n",
       "       0.69070195, 0.69571299, 0.69894408, 0.62700055, 0.68629578,\n",
       "       0.68101084, 0.69203391, 0.69344703, 0.69525201])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05197515e-01, 8.19661535e-02, 5.29922391e-02, 1.48602808e-01,\n",
       "       1.21608257e-01, 2.02292606e-01, 2.49384608e-01, 9.09343581e-03,\n",
       "       9.55218233e-03, 0.00000000e+00, 0.00000000e+00, 8.34279106e-03,\n",
       "       3.08123547e-05, 8.33272236e-03, 1.72207634e-03, 0.00000000e+00,\n",
       "       8.81792385e-04])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'admissionweight', 'admissionheight', 'respiratoryrate',\n",
       "       'sodium', 'heartrate', 'meanbp', 'gender_Female', 'gender_Male',\n",
       "       'gender_Other', 'gender_Unknown', 'ethnicity_African American',\n",
       "       'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic',\n",
       "       'ethnicity_Native American', 'ethnicity_Other/Unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'ethnicity_Native American'),\n",
       " (0.0, 'gender_Other'),\n",
       " (0.0, 'gender_Unknown'),\n",
       " (0.0010884710496590956, 'ethnicity_Asian'),\n",
       " (0.0027251260402940698, 'ethnicity_Other/Unknown'),\n",
       " (0.004116386794745649, 'ethnicity_Hispanic'),\n",
       " (0.004561326956827826, 'ethnicity_African American'),\n",
       " (0.0064929823819860465, 'gender_Female'),\n",
       " (0.006496594029832037, 'ethnicity_Caucasian'),\n",
       " (0.007679642426821184, 'gender_Male'),\n",
       " (0.035955649796686376, 'admissionheight'),\n",
       " (0.05563679519726056, 'admissionweight'),\n",
       " (0.08608175154208986, 'age'),\n",
       " (0.11974519563072099, 'sodium'),\n",
       " (0.15526107059488312, 'respiratoryrate'),\n",
       " (0.22079887918421337, 'heartrate'),\n",
       " (0.2933601283739799, 'meanbp')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(grid_search.best_estimator_.feature_importances_, downsample_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[5086  178]\n",
      " [1409  247]]\n",
      "roc auc 0.5576699998531637\n",
      "f1 0.23738587217683804\n",
      "precision 0.290297854586251\n",
      "recall 0.14915458937198067\n",
      "mcc 0.2049670307514166\n"
     ]
    }
   ],
   "source": [
    "show_metrics(list(new_rf.predict(x_val)), list(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test == \"ALIVE\"] = 0\n",
    "y_test[y_test == \"EXPIRED\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[5044  170]\n",
      " [1452  255]]\n",
      "roc auc 0.5583901797445433\n",
      "f1 0.23921200750469043\n",
      "precision 0.2994272036736973\n",
      "recall 0.14938488576449913\n",
      "mcc 0.20967884161369352\n"
     ]
    }
   ],
   "source": [
    "show_metrics(list(new_rf.predict(x_test)), list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>admissionweight</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>respiratoryrate</th>\n",
       "      <th>sodium</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>meanbp</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>gender_Unknown</th>\n",
       "      <th>ethnicity_African American</th>\n",
       "      <th>ethnicity_Asian</th>\n",
       "      <th>ethnicity_Caucasian</th>\n",
       "      <th>ethnicity_Hispanic</th>\n",
       "      <th>ethnicity_Native American</th>\n",
       "      <th>ethnicity_Other/Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29028</td>\n",
       "      <td>62</td>\n",
       "      <td>65.9</td>\n",
       "      <td>167.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>108</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25521</td>\n",
       "      <td>79</td>\n",
       "      <td>55.2</td>\n",
       "      <td>152.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>94</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3788</td>\n",
       "      <td>69</td>\n",
       "      <td>71.2</td>\n",
       "      <td>182.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>54</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24197</td>\n",
       "      <td>61</td>\n",
       "      <td>62.4</td>\n",
       "      <td>162.6</td>\n",
       "      <td>39.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>111</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4223</td>\n",
       "      <td>77</td>\n",
       "      <td>92.0</td>\n",
       "      <td>152.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>96</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23896</td>\n",
       "      <td>68</td>\n",
       "      <td>70.0</td>\n",
       "      <td>172.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>139</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7036</td>\n",
       "      <td>73</td>\n",
       "      <td>91.4</td>\n",
       "      <td>157.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>106</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24665</td>\n",
       "      <td>57</td>\n",
       "      <td>56.7</td>\n",
       "      <td>170.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>142</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14538</td>\n",
       "      <td>52</td>\n",
       "      <td>50.8</td>\n",
       "      <td>180.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>139</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30581</td>\n",
       "      <td>72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>50</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2802 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  admissionweight  admissionheight  respiratoryrate  sodium  \\\n",
       "29028   62             65.9            167.6             40.0   131.0   \n",
       "25521   79             55.2            152.4             24.0   138.0   \n",
       "3788    69             71.2            182.9             10.0   138.0   \n",
       "24197   61             62.4            162.6             39.0   138.0   \n",
       "4223    77             92.0            152.4              4.0   141.0   \n",
       "...    ...              ...              ...              ...     ...   \n",
       "23896   68             70.0            172.7              5.0   144.0   \n",
       "7036    73             91.4            157.5             42.0   138.0   \n",
       "24665   57             56.7            170.2             33.0   139.0   \n",
       "14538   52             50.8            180.3             49.0   142.0   \n",
       "30581   72            100.0            177.0             33.0   135.0   \n",
       "\n",
       "       heartrate  meanbp  gender_Female  gender_Male  gender_Other  \\\n",
       "29028        108    65.0              0            1             0   \n",
       "25521         94    44.0              1            0             0   \n",
       "3788          54    54.0              0            1             0   \n",
       "24197        111    48.0              0            1             0   \n",
       "4223          96    53.0              1            0             0   \n",
       "...          ...     ...            ...          ...           ...   \n",
       "23896        139    40.0              0            1             0   \n",
       "7036         106    40.0              1            0             0   \n",
       "24665        142    46.0              1            0             0   \n",
       "14538        139    40.0              0            1             0   \n",
       "30581         50    64.0              1            0             0   \n",
       "\n",
       "       gender_Unknown  ethnicity_African American  ethnicity_Asian  \\\n",
       "29028               0                           0                0   \n",
       "25521               0                           0                0   \n",
       "3788                0                           0                0   \n",
       "24197               0                           0                0   \n",
       "4223                0                           0                0   \n",
       "...               ...                         ...              ...   \n",
       "23896               0                           0                0   \n",
       "7036                0                           0                0   \n",
       "24665               0                           0                0   \n",
       "14538               0                           0                0   \n",
       "30581               0                           1                0   \n",
       "\n",
       "       ethnicity_Caucasian  ethnicity_Hispanic  ethnicity_Native American  \\\n",
       "29028                    1                   0                          0   \n",
       "25521                    1                   0                          0   \n",
       "3788                     1                   0                          0   \n",
       "24197                    1                   0                          0   \n",
       "4223                     0                   1                          0   \n",
       "...                    ...                 ...                        ...   \n",
       "23896                    1                   0                          0   \n",
       "7036                     1                   0                          0   \n",
       "24665                    1                   0                          0   \n",
       "14538                    1                   0                          0   \n",
       "30581                    0                   0                          0   \n",
       "\n",
       "       ethnicity_Other/Unknown  \n",
       "29028                        0  \n",
       "25521                        0  \n",
       "3788                         0  \n",
       "24197                        0  \n",
       "4223                         0  \n",
       "...                        ...  \n",
       "23896                        0  \n",
       "7036                         0  \n",
       "24665                        0  \n",
       "14538                        0  \n",
       "30581                        0  \n",
       "\n",
       "[2802 rows x 17 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "#reshaping data\n",
    "\n",
    "downsample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_tensor = downsample_df.to_numpy()\n",
    "downsample_labels_tensor = downsample_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 17)\n",
      "(6920,)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "x_val_tensor = x_val.to_numpy()\n",
    "y_val_tensor = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(13, activation = 'relu', input_dim = 17))\n",
    "model.add(layers.Dense(8, activation = 'relu'))\n",
    "model.add(layers.Dense(3, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 13)                234       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 377\n",
      "Trainable params: 377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tedlinghu/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2802 samples, validate on 6920 samples\n",
      "Epoch 1/100\n",
      "2802/2802 [==============================] - 0s 129us/step - loss: 8.6799 - accuracy: 0.4554 - val_loss: 14.9464 - val_accuracy: 0.0614\n",
      "Epoch 2/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 3.6629 - accuracy: 0.4543 - val_loss: 0.7414 - val_accuracy: 0.7751\n",
      "Epoch 3/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.7001 - accuracy: 0.5653 - val_loss: 0.6812 - val_accuracy: 0.8889\n",
      "Epoch 4/100\n",
      "2802/2802 [==============================] - 0s 69us/step - loss: 0.6863 - accuracy: 0.5778 - val_loss: 0.7444 - val_accuracy: 0.7451\n",
      "Epoch 5/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6666 - accuracy: 0.6042 - val_loss: 0.6577 - val_accuracy: 0.8490\n",
      "Epoch 6/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.6583 - accuracy: 0.6260 - val_loss: 0.6451 - val_accuracy: 0.8484\n",
      "Epoch 7/100\n",
      "2802/2802 [==============================] - 0s 69us/step - loss: 0.6584 - accuracy: 0.6288 - val_loss: 0.5935 - val_accuracy: 0.8832\n",
      "Epoch 8/100\n",
      "2802/2802 [==============================] - 0s 71us/step - loss: 0.6509 - accuracy: 0.6260 - val_loss: 0.5644 - val_accuracy: 0.8759\n",
      "Epoch 9/100\n",
      "2802/2802 [==============================] - 0s 81us/step - loss: 0.6527 - accuracy: 0.6196 - val_loss: 0.6079 - val_accuracy: 0.8379\n",
      "Epoch 10/100\n",
      "2802/2802 [==============================] - 0s 72us/step - loss: 0.6521 - accuracy: 0.6331 - val_loss: 0.6569 - val_accuracy: 0.8290\n",
      "Epoch 11/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6480 - accuracy: 0.6306 - val_loss: 0.5379 - val_accuracy: 0.9094\n",
      "Epoch 12/100\n",
      "2802/2802 [==============================] - 0s 72us/step - loss: 0.6480 - accuracy: 0.6256 - val_loss: 0.6447 - val_accuracy: 0.7958\n",
      "Epoch 13/100\n",
      "2802/2802 [==============================] - 0s 77us/step - loss: 0.6415 - accuracy: 0.6413 - val_loss: 0.6157 - val_accuracy: 0.8354\n",
      "Epoch 14/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.6348 - accuracy: 0.6453 - val_loss: 0.5634 - val_accuracy: 0.8408\n",
      "Epoch 15/100\n",
      "2802/2802 [==============================] - 0s 76us/step - loss: 0.6376 - accuracy: 0.6395 - val_loss: 0.5889 - val_accuracy: 0.8301\n",
      "Epoch 16/100\n",
      "2802/2802 [==============================] - 0s 70us/step - loss: 0.6365 - accuracy: 0.6474 - val_loss: 0.5326 - val_accuracy: 0.8762\n",
      "Epoch 17/100\n",
      "2802/2802 [==============================] - 0s 70us/step - loss: 0.6372 - accuracy: 0.6456 - val_loss: 0.5790 - val_accuracy: 0.8305\n",
      "Epoch 18/100\n",
      "2802/2802 [==============================] - 0s 79us/step - loss: 0.6318 - accuracy: 0.6456 - val_loss: 0.7001 - val_accuracy: 0.7558\n",
      "Epoch 19/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.6298 - accuracy: 0.6549 - val_loss: 0.5690 - val_accuracy: 0.8353\n",
      "Epoch 20/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6275 - accuracy: 0.6556 - val_loss: 0.6094 - val_accuracy: 0.7874\n",
      "Epoch 21/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6323 - accuracy: 0.6499 - val_loss: 0.5834 - val_accuracy: 0.8036\n",
      "Epoch 22/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.6285 - accuracy: 0.6517 - val_loss: 0.6293 - val_accuracy: 0.7796\n",
      "Epoch 23/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.6243 - accuracy: 0.6510 - val_loss: 0.5401 - val_accuracy: 0.8337\n",
      "Epoch 24/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.6254 - accuracy: 0.6517 - val_loss: 0.6173 - val_accuracy: 0.7819\n",
      "Epoch 25/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6234 - accuracy: 0.6599 - val_loss: 0.6841 - val_accuracy: 0.7978\n",
      "Epoch 26/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6214 - accuracy: 0.6652 - val_loss: 0.6765 - val_accuracy: 0.7324\n",
      "Epoch 27/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6201 - accuracy: 0.6645 - val_loss: 0.5005 - val_accuracy: 0.8653\n",
      "Epoch 28/100\n",
      "2802/2802 [==============================] - 0s 70us/step - loss: 0.6198 - accuracy: 0.6660 - val_loss: 0.5881 - val_accuracy: 0.7903\n",
      "Epoch 29/100\n",
      "2802/2802 [==============================] - 0s 74us/step - loss: 0.6189 - accuracy: 0.6681 - val_loss: 0.6497 - val_accuracy: 0.7540\n",
      "Epoch 30/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6139 - accuracy: 0.6749 - val_loss: 0.5503 - val_accuracy: 0.8399\n",
      "Epoch 31/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6181 - accuracy: 0.6734 - val_loss: 0.6422 - val_accuracy: 0.7611\n",
      "Epoch 32/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6154 - accuracy: 0.6706 - val_loss: 0.6867 - val_accuracy: 0.6970\n",
      "Epoch 33/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6127 - accuracy: 0.6617 - val_loss: 0.5573 - val_accuracy: 0.8090\n",
      "Epoch 34/100\n",
      "2802/2802 [==============================] - 0s 72us/step - loss: 0.6131 - accuracy: 0.6724 - val_loss: 0.6445 - val_accuracy: 0.7316\n",
      "Epoch 35/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6170 - accuracy: 0.6742 - val_loss: 0.5323 - val_accuracy: 0.8136\n",
      "Epoch 36/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6116 - accuracy: 0.6709 - val_loss: 0.4835 - val_accuracy: 0.8445\n",
      "Epoch 37/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6089 - accuracy: 0.6820 - val_loss: 0.5669 - val_accuracy: 0.7824\n",
      "Epoch 38/100\n",
      "2802/2802 [==============================] - 0s 62us/step - loss: 0.6092 - accuracy: 0.6781 - val_loss: 0.5052 - val_accuracy: 0.8496\n",
      "Epoch 39/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6061 - accuracy: 0.6756 - val_loss: 0.5520 - val_accuracy: 0.8058\n",
      "Epoch 40/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6081 - accuracy: 0.6806 - val_loss: 0.5735 - val_accuracy: 0.7855\n",
      "Epoch 41/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6045 - accuracy: 0.6802 - val_loss: 0.6074 - val_accuracy: 0.7647\n",
      "Epoch 42/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6031 - accuracy: 0.6799 - val_loss: 0.5876 - val_accuracy: 0.7890\n",
      "Epoch 43/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6053 - accuracy: 0.6763 - val_loss: 0.6125 - val_accuracy: 0.7649\n",
      "Epoch 44/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6057 - accuracy: 0.6831 - val_loss: 0.5574 - val_accuracy: 0.7750\n",
      "Epoch 45/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6082 - accuracy: 0.6763 - val_loss: 0.7513 - val_accuracy: 0.6604\n",
      "Epoch 46/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6080 - accuracy: 0.6756 - val_loss: 0.5398 - val_accuracy: 0.8085\n",
      "Epoch 47/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6062 - accuracy: 0.6799 - val_loss: 0.5826 - val_accuracy: 0.7704\n",
      "Epoch 48/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6034 - accuracy: 0.6820 - val_loss: 0.5779 - val_accuracy: 0.7871\n",
      "Epoch 49/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.6063 - accuracy: 0.6777 - val_loss: 0.5226 - val_accuracy: 0.8145\n",
      "Epoch 50/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.6051 - accuracy: 0.6774 - val_loss: 0.5994 - val_accuracy: 0.7540\n",
      "Epoch 51/100\n",
      "2802/2802 [==============================] - 0s 75us/step - loss: 0.6072 - accuracy: 0.6774 - val_loss: 0.5566 - val_accuracy: 0.8006\n",
      "Epoch 52/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6037 - accuracy: 0.6777 - val_loss: 0.6714 - val_accuracy: 0.7069\n",
      "Epoch 53/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.6015 - accuracy: 0.6838 - val_loss: 0.6091 - val_accuracy: 0.7436\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.6001 - accuracy: 0.6806 - val_loss: 0.5168 - val_accuracy: 0.8185\n",
      "Epoch 55/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5998 - accuracy: 0.6792 - val_loss: 0.6244 - val_accuracy: 0.7380\n",
      "Epoch 56/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.6022 - accuracy: 0.6777 - val_loss: 0.4840 - val_accuracy: 0.8457\n",
      "Epoch 57/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6012 - accuracy: 0.6770 - val_loss: 0.5015 - val_accuracy: 0.8275\n",
      "Epoch 58/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6008 - accuracy: 0.6788 - val_loss: 0.7060 - val_accuracy: 0.6874\n",
      "Epoch 59/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.6010 - accuracy: 0.6763 - val_loss: 0.4802 - val_accuracy: 0.8348\n",
      "Epoch 60/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.5996 - accuracy: 0.6845 - val_loss: 0.4963 - val_accuracy: 0.8340\n",
      "Epoch 61/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.5985 - accuracy: 0.6831 - val_loss: 0.5831 - val_accuracy: 0.7487\n",
      "Epoch 62/100\n",
      "2802/2802 [==============================] - 0s 71us/step - loss: 0.6008 - accuracy: 0.6792 - val_loss: 0.4645 - val_accuracy: 0.8460\n",
      "Epoch 63/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5994 - accuracy: 0.6820 - val_loss: 0.4986 - val_accuracy: 0.8236\n",
      "Epoch 64/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5955 - accuracy: 0.6877 - val_loss: 0.7046 - val_accuracy: 0.6805\n",
      "Epoch 65/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.6004 - accuracy: 0.6763 - val_loss: 0.4805 - val_accuracy: 0.8478\n",
      "Epoch 66/100\n",
      "2802/2802 [==============================] - 0s 69us/step - loss: 0.5977 - accuracy: 0.6820 - val_loss: 0.6337 - val_accuracy: 0.7616\n",
      "Epoch 67/100\n",
      "2802/2802 [==============================] - 0s 69us/step - loss: 0.5966 - accuracy: 0.6838 - val_loss: 0.5368 - val_accuracy: 0.8108\n",
      "Epoch 68/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.5933 - accuracy: 0.6884 - val_loss: 0.5945 - val_accuracy: 0.7546\n",
      "Epoch 69/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.5935 - accuracy: 0.6924 - val_loss: 0.5658 - val_accuracy: 0.7756\n",
      "Epoch 70/100\n",
      "2802/2802 [==============================] - 0s 67us/step - loss: 0.5917 - accuracy: 0.6842 - val_loss: 0.5004 - val_accuracy: 0.8253\n",
      "Epoch 71/100\n",
      "2802/2802 [==============================] - 0s 70us/step - loss: 0.5967 - accuracy: 0.6927 - val_loss: 0.4877 - val_accuracy: 0.8289\n",
      "Epoch 72/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.5919 - accuracy: 0.6870 - val_loss: 0.4957 - val_accuracy: 0.8292\n",
      "Epoch 73/100\n",
      "2802/2802 [==============================] - 0s 71us/step - loss: 0.5925 - accuracy: 0.6902 - val_loss: 0.5559 - val_accuracy: 0.7981\n",
      "Epoch 74/100\n",
      "2802/2802 [==============================] - 0s 69us/step - loss: 0.5943 - accuracy: 0.6906 - val_loss: 0.5022 - val_accuracy: 0.8338\n",
      "Epoch 75/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.5932 - accuracy: 0.6924 - val_loss: 0.5631 - val_accuracy: 0.7835\n",
      "Epoch 76/100\n",
      "2802/2802 [==============================] - 0s 69us/step - loss: 0.5943 - accuracy: 0.6745 - val_loss: 0.5130 - val_accuracy: 0.8240\n",
      "Epoch 77/100\n",
      "2802/2802 [==============================] - 0s 70us/step - loss: 0.5910 - accuracy: 0.6941 - val_loss: 0.5031 - val_accuracy: 0.8293\n",
      "Epoch 78/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5949 - accuracy: 0.6784 - val_loss: 0.5428 - val_accuracy: 0.7792\n",
      "Epoch 79/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5912 - accuracy: 0.6881 - val_loss: 0.5514 - val_accuracy: 0.8162\n",
      "Epoch 80/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.5912 - accuracy: 0.6916 - val_loss: 0.6174 - val_accuracy: 0.7419\n",
      "Epoch 81/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.5882 - accuracy: 0.6899 - val_loss: 0.5587 - val_accuracy: 0.7828\n",
      "Epoch 82/100\n",
      "2802/2802 [==============================] - 0s 68us/step - loss: 0.5925 - accuracy: 0.6852 - val_loss: 0.6826 - val_accuracy: 0.6938\n",
      "Epoch 83/100\n",
      "2802/2802 [==============================] - 0s 65us/step - loss: 0.5891 - accuracy: 0.6952 - val_loss: 0.5556 - val_accuracy: 0.8220\n",
      "Epoch 84/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5907 - accuracy: 0.6913 - val_loss: 0.5260 - val_accuracy: 0.8179\n",
      "Epoch 85/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.5922 - accuracy: 0.6827 - val_loss: 0.4789 - val_accuracy: 0.8396\n",
      "Epoch 86/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5915 - accuracy: 0.6913 - val_loss: 0.4744 - val_accuracy: 0.8448\n",
      "Epoch 87/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5923 - accuracy: 0.6877 - val_loss: 0.6343 - val_accuracy: 0.7384\n",
      "Epoch 88/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5898 - accuracy: 0.6842 - val_loss: 0.6793 - val_accuracy: 0.6892\n",
      "Epoch 89/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.5946 - accuracy: 0.6888 - val_loss: 0.4895 - val_accuracy: 0.8262\n",
      "Epoch 90/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5917 - accuracy: 0.6938 - val_loss: 0.6745 - val_accuracy: 0.7100\n",
      "Epoch 91/100\n",
      "2802/2802 [==============================] - 0s 63us/step - loss: 0.5918 - accuracy: 0.6852 - val_loss: 0.5800 - val_accuracy: 0.7555\n",
      "Epoch 92/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5924 - accuracy: 0.6892 - val_loss: 0.5815 - val_accuracy: 0.7539\n",
      "Epoch 93/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5877 - accuracy: 0.6959 - val_loss: 0.4766 - val_accuracy: 0.8231\n",
      "Epoch 94/100\n",
      "2802/2802 [==============================] - 0s 66us/step - loss: 0.5902 - accuracy: 0.6934 - val_loss: 0.6185 - val_accuracy: 0.7220\n",
      "Epoch 95/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5915 - accuracy: 0.6874 - val_loss: 0.5733 - val_accuracy: 0.7656\n",
      "Epoch 96/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5900 - accuracy: 0.6881 - val_loss: 0.5973 - val_accuracy: 0.7513\n",
      "Epoch 97/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5914 - accuracy: 0.6874 - val_loss: 0.6067 - val_accuracy: 0.7434\n",
      "Epoch 98/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5916 - accuracy: 0.6867 - val_loss: 0.5173 - val_accuracy: 0.8273\n",
      "Epoch 99/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5892 - accuracy: 0.6874 - val_loss: 0.6189 - val_accuracy: 0.7451\n",
      "Epoch 100/100\n",
      "2802/2802 [==============================] - 0s 64us/step - loss: 0.5923 - accuracy: 0.6927 - val_loss: 0.5488 - val_accuracy: 0.7912\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(downsample_tensor, downsample_labels_tensor, epochs = 100, validation_data = (x_val_tensor, y_val_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [14.946428078447463,\n",
       "  0.7414030356214225,\n",
       "  0.6812348214188063,\n",
       "  0.7443535086047443,\n",
       "  0.6576548652152795,\n",
       "  0.6451232241757343,\n",
       "  0.5935355843836172,\n",
       "  0.564421632110728,\n",
       "  0.6078706092917161,\n",
       "  0.6569356175516382,\n",
       "  0.5379233824035335,\n",
       "  0.6447023189136748,\n",
       "  0.6157375062821229,\n",
       "  0.5634054516092201,\n",
       "  0.5888901781484571,\n",
       "  0.5325522314606375,\n",
       "  0.5789573957465287,\n",
       "  0.7000920226808228,\n",
       "  0.56900163372128,\n",
       "  0.6094435145400163,\n",
       "  0.5834196961684034,\n",
       "  0.6292779331262401,\n",
       "  0.5400617944022824,\n",
       "  0.6172756221253058,\n",
       "  0.6840855787255171,\n",
       "  0.6764786713385168,\n",
       "  0.5004603226060812,\n",
       "  0.5880750336398968,\n",
       "  0.6496729188571776,\n",
       "  0.5502642661160816,\n",
       "  0.6422037837133242,\n",
       "  0.6866503022998743,\n",
       "  0.5573004324312155,\n",
       "  0.6444863083734678,\n",
       "  0.5323134620754705,\n",
       "  0.4835145515513558,\n",
       "  0.566933997242437,\n",
       "  0.5052114470845702,\n",
       "  0.5519735578856716,\n",
       "  0.5735131068036735,\n",
       "  0.6074249078772661,\n",
       "  0.5875976010554098,\n",
       "  0.6124882232247061,\n",
       "  0.5573899063071763,\n",
       "  0.751308734361836,\n",
       "  0.5397962419972944,\n",
       "  0.58260780483312,\n",
       "  0.5779385230444759,\n",
       "  0.5225745857795538,\n",
       "  0.5993861585683217,\n",
       "  0.5566263681202266,\n",
       "  0.6714152973511316,\n",
       "  0.609088534426827,\n",
       "  0.5167534144627566,\n",
       "  0.6243624273752202,\n",
       "  0.48398320964306074,\n",
       "  0.5014556679422456,\n",
       "  0.7060250450420931,\n",
       "  0.48020521478156825,\n",
       "  0.4962570762358649,\n",
       "  0.5830854241558582,\n",
       "  0.4645286562814878,\n",
       "  0.49861955119006207,\n",
       "  0.7045838763948121,\n",
       "  0.48048414653436294,\n",
       "  0.6336960465921831,\n",
       "  0.5368247163089025,\n",
       "  0.5945229154101686,\n",
       "  0.5658027896302283,\n",
       "  0.5003990380061155,\n",
       "  0.48766233693657585,\n",
       "  0.49569237983295683,\n",
       "  0.5558606449579228,\n",
       "  0.5022404616967792,\n",
       "  0.5631367082540699,\n",
       "  0.5129887212907648,\n",
       "  0.5031038134084271,\n",
       "  0.542840168517449,\n",
       "  0.551424252366744,\n",
       "  0.6173529835794702,\n",
       "  0.5586550696736815,\n",
       "  0.6825545465326034,\n",
       "  0.5555776026207587,\n",
       "  0.5260172147971357,\n",
       "  0.4789389085218396,\n",
       "  0.4744285038440903,\n",
       "  0.6342922298894452,\n",
       "  0.679327307546759,\n",
       "  0.489462742709011,\n",
       "  0.6744825445158633,\n",
       "  0.5800250108531445,\n",
       "  0.5815390120351934,\n",
       "  0.47655474133574205,\n",
       "  0.6184775390376934,\n",
       "  0.5732637052591136,\n",
       "  0.597330529565756,\n",
       "  0.6067391666373766,\n",
       "  0.5172976331214685,\n",
       "  0.6188536473092316,\n",
       "  0.5487895956618248],\n",
       " 'val_accuracy': [0.06141618639230728,\n",
       "  0.7751445174217224,\n",
       "  0.8888728618621826,\n",
       "  0.7450867295265198,\n",
       "  0.84898841381073,\n",
       "  0.848410427570343,\n",
       "  0.8832370042800903,\n",
       "  0.8758670687675476,\n",
       "  0.8378612995147705,\n",
       "  0.8290462493896484,\n",
       "  0.9093930721282959,\n",
       "  0.795809268951416,\n",
       "  0.835404634475708,\n",
       "  0.8407514691352844,\n",
       "  0.8300577998161316,\n",
       "  0.8761560916900635,\n",
       "  0.830491304397583,\n",
       "  0.7557803392410278,\n",
       "  0.8352600932121277,\n",
       "  0.7874277234077454,\n",
       "  0.8036127090454102,\n",
       "  0.7796242833137512,\n",
       "  0.8336704969406128,\n",
       "  0.7819364070892334,\n",
       "  0.7978323698043823,\n",
       "  0.7323699593544006,\n",
       "  0.8653179407119751,\n",
       "  0.7903178930282593,\n",
       "  0.7540462613105774,\n",
       "  0.8398844003677368,\n",
       "  0.7611271739006042,\n",
       "  0.6969653367996216,\n",
       "  0.8089595437049866,\n",
       "  0.7316473722457886,\n",
       "  0.8135837912559509,\n",
       "  0.8445086479187012,\n",
       "  0.7823699712753296,\n",
       "  0.8495664596557617,\n",
       "  0.8057803511619568,\n",
       "  0.7855491042137146,\n",
       "  0.7647398710250854,\n",
       "  0.7890173196792603,\n",
       "  0.7648844122886658,\n",
       "  0.7749999761581421,\n",
       "  0.660404622554779,\n",
       "  0.8085260391235352,\n",
       "  0.7703757286071777,\n",
       "  0.7871387004852295,\n",
       "  0.8144508600234985,\n",
       "  0.7540462613105774,\n",
       "  0.8005780577659607,\n",
       "  0.7069364190101624,\n",
       "  0.7436416149139404,\n",
       "  0.8184971213340759,\n",
       "  0.7380057573318481,\n",
       "  0.8456647396087646,\n",
       "  0.8274566531181335,\n",
       "  0.6874277591705322,\n",
       "  0.8348265886306763,\n",
       "  0.8339595198631287,\n",
       "  0.748699426651001,\n",
       "  0.8459537625312805,\n",
       "  0.8235549330711365,\n",
       "  0.6804913282394409,\n",
       "  0.8478323817253113,\n",
       "  0.7615606784820557,\n",
       "  0.8108381628990173,\n",
       "  0.7546243071556091,\n",
       "  0.7755780220031738,\n",
       "  0.8252890110015869,\n",
       "  0.8289017081260681,\n",
       "  0.829190731048584,\n",
       "  0.7981213927268982,\n",
       "  0.8338150382041931,\n",
       "  0.7835260033607483,\n",
       "  0.8239884376525879,\n",
       "  0.8293352723121643,\n",
       "  0.7791907787322998,\n",
       "  0.8161849975585938,\n",
       "  0.74190753698349,\n",
       "  0.782803475856781,\n",
       "  0.6937861442565918,\n",
       "  0.8219653367996216,\n",
       "  0.8179190754890442,\n",
       "  0.839595377445221,\n",
       "  0.844797670841217,\n",
       "  0.7384393215179443,\n",
       "  0.6891618371009827,\n",
       "  0.8261560797691345,\n",
       "  0.7099710702896118,\n",
       "  0.755491316318512,\n",
       "  0.7539017200469971,\n",
       "  0.8231213688850403,\n",
       "  0.7219653129577637,\n",
       "  0.7656069397926331,\n",
       "  0.751300573348999,\n",
       "  0.7433525919914246,\n",
       "  0.8273121118545532,\n",
       "  0.7450867295265198,\n",
       "  0.7911849617958069],\n",
       " 'loss': [8.679936100635079,\n",
       "  3.662923799890182,\n",
       "  0.7001388041484705,\n",
       "  0.6862613087803189,\n",
       "  0.6666011502281587,\n",
       "  0.6582771422265684,\n",
       "  0.6584494049254696,\n",
       "  0.6509105698880258,\n",
       "  0.6527076940465024,\n",
       "  0.652106353676719,\n",
       "  0.6480011229511672,\n",
       "  0.6479934950456885,\n",
       "  0.6414825942242341,\n",
       "  0.6348457540000532,\n",
       "  0.6376176421809078,\n",
       "  0.6364710349682652,\n",
       "  0.6372073900691106,\n",
       "  0.6318096980122819,\n",
       "  0.6298497123517453,\n",
       "  0.627499256535652,\n",
       "  0.6322739452315091,\n",
       "  0.6284536691242929,\n",
       "  0.6243360293583731,\n",
       "  0.6253838388941954,\n",
       "  0.6233797875750839,\n",
       "  0.6213548180037614,\n",
       "  0.620097584251333,\n",
       "  0.6198413004456547,\n",
       "  0.6188856987847676,\n",
       "  0.6139221024206926,\n",
       "  0.6181102346982554,\n",
       "  0.6153519246554392,\n",
       "  0.6126867468913566,\n",
       "  0.6131351642060672,\n",
       "  0.6170085060817697,\n",
       "  0.6116365227505277,\n",
       "  0.6088507159704144,\n",
       "  0.6092159254562847,\n",
       "  0.606085889897629,\n",
       "  0.6080829868309844,\n",
       "  0.6045481740024411,\n",
       "  0.6031364746216278,\n",
       "  0.605329842460232,\n",
       "  0.6057241128905172,\n",
       "  0.6081874706675375,\n",
       "  0.6080048468860024,\n",
       "  0.6062004353896283,\n",
       "  0.6033996808197054,\n",
       "  0.6063073546353789,\n",
       "  0.6050869925034038,\n",
       "  0.6072456230443346,\n",
       "  0.6037448898202432,\n",
       "  0.6015430475285358,\n",
       "  0.6000534587039171,\n",
       "  0.5998042280294485,\n",
       "  0.6021706406173325,\n",
       "  0.6012065102592866,\n",
       "  0.6007809616003098,\n",
       "  0.6010080333014712,\n",
       "  0.599584992318218,\n",
       "  0.5985154318945651,\n",
       "  0.6008137586625621,\n",
       "  0.5994224168418731,\n",
       "  0.5954720176687247,\n",
       "  0.6003722274924584,\n",
       "  0.5976666107848233,\n",
       "  0.5965755491874458,\n",
       "  0.5933304770260007,\n",
       "  0.5934695467023149,\n",
       "  0.5917095251376079,\n",
       "  0.5967326537359621,\n",
       "  0.5919443074930233,\n",
       "  0.5924936735910828,\n",
       "  0.594255915120361,\n",
       "  0.5931737345512385,\n",
       "  0.5942910636517935,\n",
       "  0.5910276956510578,\n",
       "  0.5948866231368322,\n",
       "  0.5911732118185888,\n",
       "  0.5912241787250173,\n",
       "  0.5881575241759366,\n",
       "  0.5924819483236277,\n",
       "  0.5890580781607182,\n",
       "  0.5907006679391282,\n",
       "  0.5922275615283032,\n",
       "  0.5914578964929764,\n",
       "  0.5923027608498431,\n",
       "  0.5898355226870693,\n",
       "  0.5945719513273682,\n",
       "  0.5917428711709766,\n",
       "  0.5917633545134937,\n",
       "  0.5923594724357681,\n",
       "  0.5876937889780511,\n",
       "  0.5902233647925781,\n",
       "  0.5914834326373773,\n",
       "  0.5900449686012976,\n",
       "  0.5914223741668194,\n",
       "  0.5916026625609415,\n",
       "  0.589159693103616,\n",
       "  0.5922976060478624],\n",
       " 'accuracy': [0.455389,\n",
       "  0.45431834,\n",
       "  0.5653105,\n",
       "  0.5778016,\n",
       "  0.6042113,\n",
       "  0.62598145,\n",
       "  0.6288366,\n",
       "  0.62598145,\n",
       "  0.61955744,\n",
       "  0.6331192,\n",
       "  0.63062096,\n",
       "  0.62562454,\n",
       "  0.6413276,\n",
       "  0.6452534,\n",
       "  0.6395432,\n",
       "  0.6473947,\n",
       "  0.6456103,\n",
       "  0.6456103,\n",
       "  0.65488935,\n",
       "  0.6556032,\n",
       "  0.6498929,\n",
       "  0.65167737,\n",
       "  0.6509636,\n",
       "  0.65167737,\n",
       "  0.6598858,\n",
       "  0.6652391,\n",
       "  0.66452533,\n",
       "  0.66595286,\n",
       "  0.6680942,\n",
       "  0.6748751,\n",
       "  0.67344755,\n",
       "  0.6705924,\n",
       "  0.6616702,\n",
       "  0.6723769,\n",
       "  0.6741613,\n",
       "  0.67094934,\n",
       "  0.68201286,\n",
       "  0.67808706,\n",
       "  0.67558885,\n",
       "  0.6805853,\n",
       "  0.6802284,\n",
       "  0.6798715,\n",
       "  0.6763026,\n",
       "  0.68308353,\n",
       "  0.6763026,\n",
       "  0.67558885,\n",
       "  0.6798715,\n",
       "  0.68201286,\n",
       "  0.6777302,\n",
       "  0.6773733,\n",
       "  0.6773733,\n",
       "  0.6777302,\n",
       "  0.6837973,\n",
       "  0.6805853,\n",
       "  0.67915773,\n",
       "  0.6777302,\n",
       "  0.67701644,\n",
       "  0.6788009,\n",
       "  0.6763026,\n",
       "  0.68451107,\n",
       "  0.68308353,\n",
       "  0.67915773,\n",
       "  0.68201286,\n",
       "  0.68772304,\n",
       "  0.6763026,\n",
       "  0.68201286,\n",
       "  0.6837973,\n",
       "  0.6884368,\n",
       "  0.6923626,\n",
       "  0.68415415,\n",
       "  0.69271946,\n",
       "  0.6870093,\n",
       "  0.69022125,\n",
       "  0.69057816,\n",
       "  0.6923626,\n",
       "  0.6745182,\n",
       "  0.69414705,\n",
       "  0.67844397,\n",
       "  0.68807995,\n",
       "  0.69164884,\n",
       "  0.6898644,\n",
       "  0.68522483,\n",
       "  0.6952177,\n",
       "  0.6912919,\n",
       "  0.6827266,\n",
       "  0.6912919,\n",
       "  0.68772304,\n",
       "  0.68415415,\n",
       "  0.6887937,\n",
       "  0.69379014,\n",
       "  0.68522483,\n",
       "  0.68915063,\n",
       "  0.6959315,\n",
       "  0.6934333,\n",
       "  0.6873662,\n",
       "  0.68807995,\n",
       "  0.6873662,\n",
       "  0.68665236,\n",
       "  0.6873662,\n",
       "  0.69271946]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('hi')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('hi')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tensor = x_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = model.predict(x_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras[y_pred_keras >= 0.5 ]= 1\n",
    "y_pred_keras[y_pred_keras < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6921"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156     0\n",
       "1224     0\n",
       "18287    0\n",
       "22231    0\n",
       "8788     0\n",
       "        ..\n",
       "25691    0\n",
       "31760    0\n",
       "11467    0\n",
       "15175    0\n",
       "12661    0\n",
       "Name: label, Length: 6921, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[5218  192]\n",
      " [1278  233]]\n",
      "roc auc 0.559356340624698\n",
      "f1 0.24070247933884298\n",
      "precision 0.2691946577238247\n",
      "recall 0.1542025148908008\n",
      "mcc 0.20427278296717571\n"
     ]
    }
   ],
   "source": [
    "show_metrics(list(y_pred_keras), list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
